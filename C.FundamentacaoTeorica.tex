
%                                           Fundamentação Teórica


\chapter{FUNDAMENTAÇÃO TEÓRICA} \label{Fund.Teorica}
\thispagestyle{empty} %Oculta o numero da primeira pagina do capitulo



Este capítulo trata de alguns assuntos importantes para a compreensão do trabalho, tais como: Redes Neurais Artificiais, Perceptrons, Adaline, Madaline, Regra Delta, funções de ativação, camadas intermediárias, algoritmos de treinamento, Backpropagation, programação orientada a objetos e Java.

\vspace{3ex}
\section{Redes Neurais Artificiais} \label{Fund.Redes.Neurais}

Toda a base para a realização desse trabalho se encontra no uso uma rede neural artificial (RNA), adequada para a realização do reconhecimento de padrões entre condições anteriores às partidas e o resultado das mesmas. 
Uma RNA é um sistema de processamento de informações que possui algumas características em comum com redes neurais biológicas. O desenvolvimento da teoria de redes neurais artificiais ocorreu a partir de generalizações matemáticas de modelos de percepção humana. LAURENE FAUSETT. Para isso, algumas hipóteses são levadas em conta: Assume-se que o processamento de informações ocorre em vários elementos simples chamados neurônios; Sinais são passados entre neurônios através de uma conexão; Cada conexão possui um peso associado, o qual, em redes neurais artificiais típicas, multiplicam o sinal transmitido; Cada neurônio possui uma função de ativação, a qual determina o sinal de saída com base na soma dos sinais de entrada. Um modelo completo de um neurônio, com base nas hipóteses acima, está mostrado na \autoref{neuronioCompleto}.

\begin{figure}[htbp]
	\centering
	  \includegraphics[angle=0, width=350pt, height=175pt]{D:/PFC/LaTex/Soccer-Wizard-LaTeX/figuras/modelo_de_neuronio.jpg}
		\caption{Modelo completo de um neurônio \citep{Haykin99}}
	  \label{neuronioCompleto}
\end{figure}

\vspace{3ex}
\subsection{McCulloch-Pitts} \label{McCulloch}


O primeiro modelo de neurônio artificial foi concebido por Warren McCulloth e Walter Pitts \citep{McCulloth43}. Algumas das regras de funcionamento desses neurônios são aplicadas ainda hoje nas redes neurais modernas. 
Podemos descrever as regras que permeiam o funcionamento dos mesmos com base nas seguintes definições:
\begin{itemize}
	\item A ativação do neurônio é binária. Ou seja, para cada situação de entrada existem apenas duas saídas, ativado ou desativado;
	\item	Os neurônios são conectados diretamente por ligações, que possuem seu respectivo peso único;
	\item	Uma ligação é excitatória se seu peso é positivo, e inibitória se seu peso é negativo. Todas conexões excitatórias possuem o mesmo peso;
	\item	Cada neurônio possui um valor limiar, e sua ativação é função da soma dos pesos de entrada (excitatórios e inibitórios). A ativação ocorre quando a soma dos pesos ultrapassa o valor limiar;
	\item A definição do limiar ocorre de forma que qualquer entrada não inibitória diferente de zero faça com que o neurônio não seja ativado;
	\item	É necessário um passo temporal para que o sinal passe por um link da conexão.
\end{itemize}
Um modelo completo de um neurônio, segundo as definições acima, é mostrado na \autoref{neuronioMcCulloth}.

\begin{figure}[htbp]
	\centering
	  \includegraphics[angle=0, width=300pt, height=175pt]{D:/PFC/LaTex/Soccer-Wizard-LaTeX/figuras/McCulloch-Pitts.jpg}
		\caption{Neurônio de McCulloch-Pitts \citep{Fausett94}}
	  \label{neuronioMcCulloth}
\end{figure}


A função de ativação (degrau) desse neurônio é dado segunda a \autoref{ativacaoMcCulloth}, onde Yin é a soma das entradas de cada um dos neurônios, conforme \autoref{entradaMcCulloth}. O limiar do neurônio é dado pela \autoref{limiarMcCulloth}.

\begin{equation} \label{ativacaoMcCulloth}
f(y_\textit{in})=\begin{cases}
1 & \text{se } Y_{in} > \theta \cr
0 & \text{se } Y_{in} \leq \theta
\end{cases}
\end{equation}

\begin{equation} \label{entradaMcCulloth}
Y_{in} = n \cdot w + m \cdot p
\end{equation}

\begin{equation} \label{limiarMcCulloth}
\theta = n \cdot w - p
\end{equation}

\vspace{3ex}
\subsection{Bias} \label{Bias}


O uso de um limiar para definir a ativação do neurônio pode ser substituído pelo uso de um bias. O bias age exatamente como o peso de uma conexão cuja entrada é sempre 1 \citep{Fausett94}, conforme mostrado na \autoref{neuronioBias}.

\begin{figure}[htbp]
	\centering
	  \includegraphics[angle=0, width=300pt, height=175pt]{D:/PFC/LaTex/Soccer-Wizard-LaTeX/figuras/Bias.jpg}
		\caption{Bias "b" em uma RNA}
	  \label{neuronioBias}
\end{figure}

O uso do bias ou do limiar são equivalentes. Sua importância se mostra durante a análise da separabilidade linear de um problema, conforme mostrado na \autoref{SeparabilidadeLinear}, e durante a análise de convergência do erro, não tratada nesse trabalho.

A diferença de aplicação entre as duas técnicas é dada pela função de ativação do neurônio, que com o uso do bias fica escrita conforme a \autoref{ativacaoBias}.

\begin{equation} \label{ativacaoBias}
f(y_\textit{in})=\begin{cases}
1 & \text{se } Y_{in} > 0 \cr
0 & \text{se } Y_{in} \leq 0
\end{cases}
\end{equation}


\vspace{3ex}
\subsection{Separabilidade Linear} \label{SeparabilidadeLinear}


Para uma determinada rede, a resposta está confinada entre dois valores (1 ou 0, sim ou não, -1 ou 1, etc...). Existe uma fronteira, chamada \emph{fronteira de decisão} \autoref{fronteiraDecisaoOU} que delimitada as regiões em que a resposta assume um ou outro valor.

\begin{figure}[htbp]
	\centering
	  \includegraphics[angle=0, width=200pt, height=200pt]{D:/PFC/LaTex/Soccer-Wizard-LaTeX/figuras/fronteiraDecisaoXOR.jpg}
		\caption{Fronteira e Regiões de decisão para a função lógica \emph{OU} \citep{Fausett94}}
	  \label{fronteiraDecisaoOU}
\end{figure}

A \autoref{fronteiraDecisao} mostra a relação que determina essa fronteira para funções de ativação do tipo degrau. Dependendo do número de entradas na rede, essa equação pode representar uma linha, um plano ou um hiperplano.

\begin{equation} \label{fronteiraDecisao}
b + \sum_i x_i \cdot w_i = 0
\end{equation}

Diz-se que um problema é linearmente separável caso existam pesos (e bias) suficientes para que todos vetores de entrada do conjunto de treinamento sejam separados pela fronteira de decisão em dois grupos, de forma que os vetores cujas saídas sejam positivas fiquem todos em um grupo, e os vetores com saídas negativas fiquem em outro. Essas duas regiões são geralmente chamadas de \emph{regiões de decisão} (\autoref{fronteiraDecisaoOU}).

\cite{Minsky69} mostraram que problemas não linearmente separáveis, são impossíveis de serem resolvidos por redes de apenas uma camada. É possível demonstrar também que redes de várias camadas, com funções de ativação lineares, também são incapazes de resolver tais problemas.

A inclusão de um bias pode transformar um problema linearmente inseparável (e portanto incapaz de ser resolvido com os métodos já apresentados) em um problema que pode ser resolvido. Isso é possível graças a adição de uma nova conexão de entrada, que será usada como valor constante para o bias. Essa nova conexão aumenta o conjunto de entradas, fornecendo mais um grau de liberdade para a rede.

\vspace{3ex}
\subsection{Representação dos dados} \label{RepresentaçãoDados}


No início dos estudos de redes neurais, a representação de dados se dava na forma binária, ou seja, utilizando 1 para reforço positivo e 0 para reforço negativo. Essa representação inicial não é, de modo geral, recomendada.

A forma bipolar é uma alternativa bastante eficiente. Essa representação utiliza 1 para reforço positivo e -1 para reforço negativo. Assim como a inclusão de um bias, a simples mudança da representação de dados para a forma bipolar pode transformar um problema sem solução em um problema que pode ser resolvido.

Caso o problema proposto requeira da rede uma generalização dos dados de entrada, o uso da forma bipolar é altamente indicado. A representação bipolar permite que dados não disponíveis sejam adotados com valor 0 de entrada, não fornecendo assim reforço positivo ou negativo.

Ao contrário do que acontece na forma binária, a representação bipolar também é mais eficiente do ponto de vista do treinamento. Por exemplo, em uma rede treinada pelo método de Hebb (\autoref{AprendizadoHebb}), para conjuntos de sinais entrada cujo resultado da rede seja negativo (0 para binário ou -1 para bipolar), o uso da primeira representação impossibilita completamente um aprendizado da rede.


\vspace{3ex}
\subsection{Aprendizado de Hebb} \label{AprendizadoHebb}


Das regras de treinamento de redes neurais, a regra de Hebb é a mais antiga, mais simples e mais conhecida de todas. Hebb propôs seu método de treinamento tendo como base um contexto neurobiológico. \cite{Stent73} e  \cite{Changeux76} reescreveram o pensamento de Hebb de uma forma mais simples e concisa, como se segue:

\begin{itemize}
	\item Se dois neurônios em ambos os lados de uma sinapse (conexão) são ativados simultaneamente (i.e. de forma síncrona), então a força dessa sinapse é seletivamente aumentada.
	\item Se dois neurônios em ambos lados de uma sinapse são ativados de forma assíncrona, então essa sinapse é seletivamente enfraquecida ou eliminada.
\end{itemize}

A afirmação original de Hebb não incluía a segunda parte. Da mesma forma, ela também comentava apenas a respeito de neurônios sendo ativados ao mesmo tempo.

\cite{McClelland88} estenderam a regra de Hebb para que o reforço positivo da sinapse também ocorra caso os neurônios sejam ambos desativados simultaneamente. Podemos, então, complementar o pensamento anterior:

\begin{itemize}
	\item Se dois neurônios em ambos os lados de uma sinapse são DESATIVADOS simultaneamente, então a força dessa sinapse é seletivamente aumentada.
\end{itemize}

Estamos considerando inicialmente redes de apenas uma camada, onde cada conexão possui, em cada lado, apenas um neurônio de entrada e um neurônio de saída. O valor do neurônio de entrada X é multiplicado pelo peso W dessa conexão para se obter o valor do neurônio de saída Y. Seguindo essa nomenclatura e representando os dados na forma bipolar, podemos representar a atualização do peso pela regra de Hebb segundo a \autoref{HebbPesos}.

\begin{equation} \label{HebbPesos}
\Delta w_{ij} = x_i \cdot y_i
\end{equation}

Se utilizarmos a representação binária, essa equação não distingue conexões que possuem uma entrada "positiva" e uma saída "negativa" de conexões onde tanto a entrada quanto a saída são "negativas". Essa é uma das vantagens mais facilmente observáveis da utilização de dados bipolares (ao invés de binários) para a representação dos dados.


\vspace{3ex}
\subsubsection{Técnica de aprendizado} \label{TecnicaAprendizado}


Existem várias técnicas de implementação das regras de aprendizado existentes. A técnica abordada aqui nada mais é do que uma das formas mais simples e genéricas de se aplicar a regra de Hebb. O entendimento dessa técnica é crucial para a posterior compreensão das outras técnicas aplicadas nesse trabalho, que podem ser tomadas como simples variações mais elaboradas desta.

O aprendizado é dado na forma iterativa e segue o seguinte algoritmo:

\begin{enumerate}
	\item Os pesos de todas conexões são inicializados com o valor 0.
	\item Para todos os conjuntos de entradas e saídas, repetem-se os passos 3-4.
	\setlength{\itemindent}{+.5in}
	\item Para cada conexão, calculamos a variação do seu respectivo peso pela equação 6.
	\item Cada peso é atualizado conforme calculado no passo 3.
\end{enumerate}

Para esclarecer um pouco mais o algoritmo acima mostrado, segue um exemplo de sua aplicação em uma rede real com representação bipolar, onde usaremos como parâmetros de entrada a função lógica E. Buscaremos com essa rede descobrir os valores dos pesos das conexões que determinam a fronteira de decisão dessa função.

A função lógica E retorna um valor "positivo" apenas se ambas as entradas possuírem também um valor "positivo". Assim sendo, montaremos a tabela verdade dessa função conforme a \autoref{tabverdadeE}. A representação gráfica dessa rede está mostrada na \autoref{redeNeuralE}.

\begin{table}[htbp]
\caption{Tabela Verdade para a função lógica E}
\setlength{\tabcolsep}{24pt}
\begin{center}
\begin{tabular}{c c c c c}
\multicolumn{3}{c}{Entradas} & & Saída \\
Bias & $X_1$ & $X_2$ & & Y \\
1 & 1 & 1 & & 1 \\
1 & 1 & -1 & & -1 \\
1 & -1 & 1 & & -1 \\
1 & -1 & -1 & & -1
\end{tabular}
\end{center}
\label{tabverdadeE}
\end{table}

\begin{figure}[htbp]
	\centering
	  \includegraphics[angle=0, width=300pt, height=175pt]{D:/PFC/LaTex/Soccer-Wizard-LaTeX/figuras/redeNeuralE.jpg}
		\caption{RNA para a função lógica E}
	  \label{redeNeuralE}
\end{figure}

Iniciamos o treinamento conforme o passo 1 do algoritmo. Fazemos então os valores de $w_0=0, w_1=0$ e $w_2=0$.

Utilizaremos o primeiro par de entradas (1 ,1). Assim, calculamos o valor da variação dos pesos conforme a \autoref{HebbPesos}. O resultado é mostrado na \autoref{pesosPrimeiroPar}.

\begin{table}[h]
\caption{Variação dos pesos para o primeiro par de entradas}
\setlength{\tabcolsep}{18pt}
\begin{center}
\begin{tabular}{*{8}{c}}
\multicolumn{3}{c}{Entrada} & \multicolumn{2}{c}{Saída desejada} & \multicolumn{3}{c}{Variação dos pesos ($\Delta w$)} \\
1 & $X_1$ & $X_2$ & \multicolumn{2}{c}{Y} & $\Delta w_0$ & $\Delta w_1$ & $\Delta w_2$ \\
1 & 1 & 1 & \multicolumn{2}{c}{1} & 1 & 1 & 1 \\
\end{tabular}
\end{center}
\label{pesosPrimeiroPar}
\end{table}

Na sequência, atualizamos os pesos com os resultados da \autoref{resultadosPrimeiroPar}.

\begin{equation} \label{resultadosPrimeiroPar}
\begin{cases}
w_0=0+\Delta w_0 = 1 \cr
w_1=0+\Delta w_1 = 1 \cr
w_2=0+\Delta w_2 = 1
\end{cases}
\end{equation}

Repetimos o procedimento para o segundo par de entradas (1, -1). Assim, calculamos o valor da variação dos pesos conforme a \autoref{HebbPesos}. O resultado é mostrado na \autoref{pesosSegundoPar}.

\begin{table}[h]
\caption{Variação dos pesos para o segundo par de entradas}
\setlength{\tabcolsep}{18pt}
\begin{center}
\begin{tabular}{*{8}{c}}
\multicolumn{3}{c}{Entrada} & \multicolumn{2}{c}{Saída desejada} & \multicolumn{3}{c}{Variação dos pesos ($\Delta w$)} \\
1 & $X_1$ & $X_2$ & \multicolumn{2}{c}{Y} & $\Delta w_0$ & $\Delta w_1$ & $\Delta w_2$ \\
1 & 1 & -1 & \multicolumn{2}{c}{-1} & -1 & -1 & 1 \\
\end{tabular}
\end{center}
\label{pesosSegundoPar}
\end{table}

Na sequência, atualizamos os pesos com os resultados da \autoref{resultadosSegundoPar}.

\begin{equation} \label{resultadosSegundoPar}
\begin{cases}
w_0=1+\Delta w_0 = 0 \cr
w_1=1+\Delta w_1 = 0 \cr
w_2=1+\Delta w_2 = 2
\end{cases}
\end{equation}

Repetimos o procedimento para o terceiro par de entradas (-1, 1). Calculamos o valor da variação dos pesos conforme a \autoref{HebbPesos}. O resultado é mostrado na \autoref{pesosTerceiroPar}.

\begin{table}[h]
\caption{Variação dos pesos para o terceiro par de entradas}
\setlength{\tabcolsep}{18pt}
\begin{center}
\begin{tabular}{*{8}{c}}
\multicolumn{3}{c}{Entrada} & \multicolumn{2}{c}{Saída desejada} & \multicolumn{3}{c}{Variação dos pesos ($\Delta w$)} \\
1 & $X_1$ & $X_2$ & \multicolumn{2}{c}{Y} & $\Delta w_0$ & $\Delta w_1$ & $\Delta w_2$ \\
1 & -1 & 1 & \multicolumn{2}{c}{-1} & -1 & 1 & -1 \\
\end{tabular}
\end{center}
\label{pesosTerceiroPar}
\end{table}

Na sequência, atualizamos os pesos com os resultados da \autoref{resultadosTerceiroPar}.

\begin{equation} \label{resultadosTerceiroPar}
\begin{cases}
w_0=0+\Delta w_0 = -1 \cr
w_1=0+\Delta w_1 = 1 \cr
w_2=2+\Delta w_2 = 1
\end{cases}
\end{equation}

Repetimos uma última vez o procedimento para o quarto par de entradas (-1, -1). Calculamos o valor da variação dos pesos conforme a \autoref{HebbPesos}. O resultado é mostrado na \autoref{pesosQuartoPar}.

\begin{table}[h]
\caption{Variação dos pesos para o quarto par de entradas}
\setlength{\tabcolsep}{18pt}
\begin{center}
\begin{tabular}{*{8}{c}}
\multicolumn{3}{c}{Entrada} & \multicolumn{2}{c}{Saída desejada} & \multicolumn{3}{c}{Variação dos pesos ($\Delta w$)} \\
1 & $X_1$ & $X_2$ & \multicolumn{2}{c}{Y} & $\Delta w_0$ & $\Delta w_1$ & $\Delta w_2$ \\
1 & -1 & -1 & \multicolumn{2}{c}{-1} & -1 & 1 & 1 \\
\end{tabular}
\end{center}
\label{pesosQuartoPar}
\end{table}

Na sequência, atualizamos os pesos com os resultados da \autoref{resultadosQuartoPar}.

\begin{equation} \label{resultadosQuartoPar}
\begin{cases}
w_0=-1+\Delta w_0 = -2 \cr
w_1=1+\Delta w_1 = 2 \cr
w_2=1+\Delta w_2 = 2
\end{cases}
\end{equation}

Terminamos assim o treinamento e a rede resultante é mostrada na \autoref{EResolvida}.

\begin{figure}[htbp]
	\centering
	  \includegraphics[angle=0, width=300pt, height=175pt]{D:/PFC/LaTex/Soccer-Wizard-LaTeX/figuras/redeEresolvida.jpg}
		\caption{RNA resolvida para a função lógica \emph{E}}
	  \label{EResolvida}
\end{figure}

Essa configuração de pesos nos fornece uma fronteira de decisão em forma de reta, que pode ser encontrada utilizando a \autoref{equacaoReta}. A equação da reta resultante do exemplo acima é dada pela \autoref{retaResultado} e está mostrada na \autoref{fronteiraDecisaoE}.


\begin{equation} \label{equacaoReta}
1 + X_1 + X_2 = 0
\end{equation}

\begin{equation} \label{retaResultado}
X_2 = -X_1 + 1
\end{equation}

\begin{figure}[htbp]
	\centering
	  \includegraphics[angle=0, width=300pt, height=175pt]{D:/PFC/LaTex/Soccer-Wizard-LaTeX/figuras/fronteiraDecisaoE.png}
		\caption{Fronteira de decisão da função lógica \emph{E}}
	  \label{fronteiraDecisaoE}
\end{figure}

Podemos notar que apesar de os pesos terem sido alterados pelo último loop, a equação da reta (e consequentemente a fronteira de decisão) não é alterada após o mesmo. Isso significa que o treinamento já havia encontrado a solução do problema antes do fim do algoritmo. Como será mostrado mais adiante, outras técnicas de treinamento podem continuar indefinidamente, repetindo os vetores de entrada, refazendo os cálculos sem fim. Nesses casos, uma condição de parada deverá ser adotada.


\vspace{3ex}
\subsection{Perceptron} \label{Perceptron}


Redes com um modelo de treinamento iterativo e supervisionado foram propostas por Frank Rosenblatt em \citeyear{Rosenblatt62}. Ele as chamou de Perceptrons e elas tiveram um grande impacto nos estudos de redes neurais artificiais. Isso se deve ao fato de que a regra de convergência dos perceptrons é mais poderosa do que sua antecessora, a regra de Hebb. Além disso, sob determinadas condições, é possível provar matematicamente a convergência de seu procedimento de aprendizado iterativo. Basicamente, ela consiste de um simples neurônio com pesos sinápticos e bias ajustáveis.

Um perceptron particularmente simples utilizava valores binários de entrada e saída, contudo a função de ativação do neurônio de saída poderia retornar valores de -1, 0 ou 1 durante o aprendizado. A possibilidade de 3 diferentes valores só ocorre graças ao novo tipo de função de ativação, onde o valor do limiar passou a delimitar uma região intermediária, e não apenas um valor limítrofe entre saídas positivas e negativas. Essa função é descrita pela \autoref{funcaoAtivacaoPerceptron}.

\begin{equation} \label{entradaPerceptron}
Y_{in} = \sum_i x_i \cdot w_i
\end{equation}

\begin{equation} \label{funcaoAtivacaoPerceptron}
f(Y_{in})=\begin{cases}
1 & \text{se } Y_{in} > \theta \cr
0 & \text{se } -\theta \leq Y_{in} \leq \theta \cr
-1 & \text{se } Y_{in} < \theta \cr
\end{cases}
\end{equation}

Para se atualizar os pesos das ligações durante o treinamento usamos a equação 11. Tal equação apresenta um novo parâmetro, chamado de taxa de aprendizado, que é um valor constante determinado antes do início do treinamento.

\begin{equation} \label{pesosPerceptron}
\Delta w_i = \alpha \cdot x_i \cdot t
\end{equation}

Observando a função de ativação de saída, que retorna valores de -1, 0 ou 1, e a saída real (Target t) que deve ter valores de -1 ou 1, podemos concluir alguns pontos importantes relacionados a esse perceptron.

\begin{itemize}
	\item A rede não diferencia situações onde, por exemplo, a saída real é -1 e a saída calculada é 0 ou 1. Em ambos os casos os pesos são atualizados, de maneira igual, e o sinal do erro informa se os mesmos devem aumentar ou diminuir.
	\item Apenas conexões de entrada com valores diferentes de 0 possuem seus pesos atualizados.
	\item Padrões de entrada que não produzem erro na saída também não têm seus pesos atualizados.
	\item Como o treinamento ocorre até que os pesos sejam tais que a saída seja correta para quaisquer padrões de entrada, e padrões sem erro não resultam em treinamento da rede, quanto mais treinada a rede estiver, menor será o seu aprendizado.
	\item O valor do limiar não mais fornece uma equação, delimitando uma fronteira de decisão, mas sim uma inequação, fornecendo uma região de "indecisão", separando a região de respostas positivas e a região de respostas negativas. Dessa forma, o valor do limiar se torna mais significativo para o processo de aprendizagem.
\end{itemize}

O treinamento do perceptron continua até que os pesos das conexões sejam tais que para todos os padrões de entrada a resposta obtida pela rede seja correta. Segundo o teorema de convergência dos perceptrons, caso tais pesos existam, eles serão encontrados em um número finito de passos do treinamento.

Ao contrário das redes mostradas até agora, no perceptron o uso do limiar e do bias não são equivalentes. Como agora eles possuem funções diferentes, ambos são necessários para que o treinamento funcione corretamente.

\vspace{3ex}
\subsubsection{Técnica de aprendizado} 

O algoritmo de aprendizado do perceptron está apresentado a seguir. Sua estrutura é semelhante à do treinamento de Hebb, porém já mais avançado e mais parecido com o algoritmo utilizado para a realização desse trabalho.
\begin{enumerate}
	\item Inicializar pesos e bias (podem ser setados em 0, por simplicidade)
	\item Definir taxa de aprendizado $0<\alpha<1$
	\item Enquanto a condição de parada não for atingida, repetem-se os passos 3-6
	\setlength{\itemindent}{+.5in}
	\item Para todos os conjuntos de entradas e saídas, repetem-se os passos 4-5
	\setlength{\itemindent}{+1in}
	\item Calcula-se o valor da saída de acordo com a \autoref{entradaPerceptron} e a \autoref{funcaoAtivacaoPerceptron}
	\item Caso a saída calculada seja diferente da saída correta, atualizam-se os pesos de acordo com a \autoref{pesosPerceptron}
	\setlength{\itemindent}{+0.5in}
	\item Caso nenhum peso tenha sido alterado no passo 3, pare. Caso contrário, continue
\end{enumerate}
		
\vspace{3ex}
\subsection{Adaline} 






