
%                                           Fundamentação Teórica


\chapter{FUNDAMENTAÇÃO TEÓRICA} \label{Fund.Teorica}
\thispagestyle{empty} %Oculta o numero da primeira pagina do capitulo



Este capítulo trata de alguns assuntos importantes para a compreensão do trabalho, tais como: redes Neurais Artificiais, Perceptrons, Adaline, Madaline, Regra Delta, funções de ativação, camadas intermediárias, algoritmos de treinamento, Backpropagation, programação orientada a objetos e Java.

\vspace{3ex}
\section{Redes Neurais Artificiais} \label{Fund.Redes.Neurais}

Toda a base para a realização desse trabalho se encontra no uso uma rede neural artificial (RNA), adequada para a realização do reconhecimento de padrões entre condições anteriores às partidas e o resultado das mesmas. 
Uma RNA é um sistema de processamento de informações que possui algumas características em comum com redes neurais biológicas. O desenvolvimento da teoria de redes neurais artificiais ocorreu a partir de generalizações matemáticas de modelos de percepção humana. \citep{Fausett94}. Para isso, algumas hipóteses são levadas em conta: assume-se que o processamento de informações ocorre em vários elementos simples chamados neurônios; sinais são passados entre neurônios através de uma conexão; cada conexão possui um peso associado, o qual, em redes neurais artificiais típicas, multiplicam o sinal transmitido; cada neurônio possui uma função de ativação, a qual determina o sinal de saída com base na soma dos sinais de entrada. Um modelo completo de um neurônio, com base nas hipóteses acima, está mostrado na \autoref{neuronioCompleto}.

\begin{figure}[htbp]
	\centering
	  \includegraphics[angle=0, width=350pt, height=175pt]{D:/PFC/LaTex/Soccer-Wizard-LaTeX/figuras/modelo_de_neuronio.jpg}
		\caption{Modelo completo de um neurônio \citep{Haykin99}}
	  \label{neuronioCompleto}
\end{figure}

\vspace{3ex}
\subsection{McCulloch-Pitts} \label{McCulloch}


O primeiro modelo de neurônio artificial foi concebido por Warren McCulloth e Walter Pitts \citep{McCulloth43}. Algumas das regras de funcionamento desses neurônios são aplicadas ainda hoje nas redes neurais modernas. 
Podemos descrever as regras que permeiam o funcionamento dos mesmos com base nas seguintes definições:
\begin{itemize}
	\item A ativação do neurônio é binária. Ou seja, para cada situação de entrada existem apenas duas saídas, ativado ou desativado;
	\item	Os neurônios são conectados diretamente por ligações, que possuem seu respectivo peso único;
	\item	Uma ligação é excitatória se seu peso é positivo, e inibitória se seu peso é negativo. Todas conexões excitatórias possuem o mesmo peso;
	\item	Cada neurônio possui um valor limiar, e sua ativação é função da soma dos pesos de entrada (excitatórios e inibitórios). A ativação ocorre quando a soma dos pesos ultrapassa o valor limiar;
	\item A definição do limiar ocorre de forma que qualquer entrada não inibitória diferente de zero faça com que o neurônio não seja ativado;
	\item	É necessário um passo temporal para que o sinal passe por um link da conexão.
\end{itemize}
Um modelo completo de um neurônio, segundo as definições acima, é mostrado na \autoref{neuronioMcCulloth}.

\begin{figure}[htbp]
	\centering
	  \includegraphics[angle=0, width=300pt, height=175pt]{D:/PFC/LaTex/Soccer-Wizard-LaTeX/figuras/McCulloch-Pitts.jpg}
		\caption{Neurônio de McCulloch-Pitts \citep{Fausett94}}
	  \label{neuronioMcCulloth}
\end{figure}


A função de ativação (degrau) desse neurônio é dado segunda a \autoref{ativacaoMcCulloth}, onde Yin é a soma das entradas de cada um dos neurônios, conforme \autoref{entradaMcCulloth}. O limiar do neurônio é dado pela \autoref{limiarMcCulloth}.

\begin{equation} \label{ativacaoMcCulloth}
f(y_\textit{in}) = \begin{cases}
1 & \text{se } Y_{in} > \theta \cr
0 & \text{se } Y_{in} \leq \theta
\end{cases}
\end{equation}

\begin{equation} \label{entradaMcCulloth}
Y_{in} = n \cdot w + m \cdot p
\end{equation}

\begin{equation} \label{limiarMcCulloth}
\theta = n \cdot w - p
\end{equation}

\vspace{3ex}
\subsection{Bias} \label{Bias}


O uso de um limiar para definir a ativação do neurônio pode ser substituído pelo uso de um bias. O bias age exatamente como o peso de uma conexão cuja entrada é sempre 1 \citep{Fausett94}, conforme mostrado na \autoref{neuronioBias}.

\begin{figure}[htbp]
	\centering
	  \includegraphics[angle=0, width=300pt, height=175pt]{D:/PFC/LaTex/Soccer-Wizard-LaTeX/figuras/Bias.jpg}
		\caption{Bias \protect\say{b} em uma RNA}
	  \label{neuronioBias}
\end{figure}

O uso do bias ou do limiar são equivalentes. Sua importância se mostra durante a análise da separabilidade linear de um problema, conforme mostrado na \autoref{SeparabilidadeLinear}, e durante a análise de convergência do erro, não tratada nesse trabalho.

A diferença de aplicação entre as duas técnicas é dada pela função de ativação do neurônio, que com o uso do bias fica escrita conforme a \autoref{ativacaoBias}.

\begin{equation} \label{ativacaoBias}
f(y_\textit{in}) = \begin{cases}
1 & \text{se } Y_{in} > 0 \cr
0 & \text{se } Y_{in} \leq 0
\end{cases}
\end{equation}


\vspace{3ex}
\subsection{Separabilidade Linear} \label{SeparabilidadeLinear}


Para uma determinada rede, a resposta está confinada entre dois valores (1 ou 0, sim ou não, -1 ou 1, etc...). Existe uma fronteira, chamada \emph{fronteira de decisão} \autoref{fronteiraDecisaoOU} que delimitada as regiões em que a resposta assume um ou outro valor \citep{Fausett94}.

\begin{figure}[htbp]
	\centering
	  \includegraphics[angle=0, width=200pt, height=200pt]{D:/PFC/LaTex/Soccer-Wizard-LaTeX/figuras/fronteiraDecisaoXOR.jpg}
		\caption{Fronteira e Regiões de decisão para a função lógica \emph{OU} \citep{Fausett94}}
	  \label{fronteiraDecisaoOU}
\end{figure}

A \autoref{fronteiraDecisao} mostra a relação que determina essa fronteira para funções de ativação do tipo degrau. Dependendo do número de entradas na rede, essa equação pode representar uma linha, um plano ou um hiperplano.

\begin{equation} \label{fronteiraDecisao}
b + \sum_i x_i \cdot w_i = 0
\end{equation}

Diz-se que um problema é linearmente separável caso existam pesos (e bias) suficientes para que todos vetores de entrada do conjunto de treinamento sejam separados pela fronteira de decisão em dois grupos, de forma que os vetores cujas saídas sejam positivas fiquem todos em um grupo, e os vetores com saídas negativas fiquem em outro. Essas duas regiões são geralmente chamadas de \emph{regiões de decisão} (\autoref{fronteiraDecisaoOU}).

\cite{Minsky69} mostraram que problemas não linearmente separáveis, são impossíveis de serem resolvidos por redes de apenas uma camada. É possível demonstrar também que redes de várias camadas, com funções de ativação lineares, também são incapazes de resolver tais problemas.

A inclusão de um bias pode transformar um problema linearmente inseparável (e portanto incapaz de ser resolvido com os métodos já apresentados) em um problema que pode ser resolvido \citep{Fausett94}. Isso é possível graças a adição de uma nova conexão de entrada, que será usada como valor constante para o bias. Essa nova conexão aumenta o conjunto de entradas, fornecendo mais um grau de liberdade para a rede.

\vspace{3ex}
\subsection{Representação dos dados} \label{RepresentaçãoDados}


No início dos estudos de redes neurais, a representação de dados se dava na forma binária, ou seja, utilizando 1 para reforço positivo e 0 para reforço negativo. Essa representação inicial não é, de modo geral, recomendada \citep{Fausett94}.

A forma bipolar é uma alternativa bastante eficiente. Essa representação utiliza 1 para reforço positivo e -1 para reforço negativo. Assim como a inclusão de um bias, a simples mudança da representação de dados para a forma bipolar pode transformar um problema sem solução em um problema que pode ser resolvido.

Caso o problema proposto requeira da rede uma generalização dos dados de entrada, o uso da forma bipolar é altamente indicado. A representação bipolar permite que dados não disponíveis sejam adotados com valor 0 de entrada, não fornecendo assim reforço positivo ou negativo.

Ao contrário do que acontece na forma binária, a representação bipolar também é mais eficiente do ponto de vista do treinamento. Por exemplo, em uma rede treinada pelo método de Hebb (\autoref{AprendizadoHebb}), para conjuntos de sinais entrada cujo resultado da rede seja negativo (0 para binário ou -1 para bipolar), o uso da primeira representação impossibilita completamente um aprendizado da rede.


\vspace{3ex}
\subsection{Aprendizado de Hebb} \label{AprendizadoHebb}


Das regras de treinamento de redes neurais, a regra de Hebb é a mais antiga, mais simples e mais conhecida de todas. Hebb propôs seu método de treinamento tendo como base um contexto neurobiológico. \cite{Stent73} e  \cite{Changeux76} reescreveram o pensamento de Hebb de uma forma mais simples e concisa, como se segue:

\begin{itemize}
	\item Se dois neurônios em ambos os lados de uma sinapse (conexão) são ativados simultaneamente (i.e. de forma síncrona), então a força dessa sinapse é seletivamente aumentada.
	\item Se dois neurônios em ambos lados de uma sinapse são ativados de forma assíncrona, então essa sinapse é seletivamente enfraquecida ou eliminada.
\end{itemize}

A afirmação original de Hebb não incluía a segunda parte. Da mesma forma, ela também comentava apenas a respeito de neurônios sendo ativados ao mesmo tempo.

\cite{McClelland88} estenderam a regra de Hebb para que o reforço positivo da sinapse também ocorra caso os neurônios sejam ambos desativados simultaneamente. Podemos, então, complementar o pensamento anterior:

\begin{itemize}
	\item Se dois neurônios em ambos os lados de uma sinapse são DESATIVADOS simultaneamente, então a força dessa sinapse é seletivamente aumentada.
\end{itemize}

Estamos considerando inicialmente redes de apenas uma camada, onde cada conexão possui, em cada lado, apenas um neurônio de entrada e um neurônio de saída. O valor do neurônio de entrada X é multiplicado pelo peso W dessa conexão para se obter o valor do neurônio de saída Y. Seguindo essa nomenclatura e representando os dados na forma bipolar, podemos representar a atualização do peso pela regra de Hebb segundo a \autoref{HebbPesos}.

\begin{equation} \label{HebbPesos}
\Delta w_{ij} = x_i \cdot y_i
\end{equation}

Se utilizarmos a representação binária, essa equação não distingue conexões que possuem uma entrada \say{positiva} e uma saída \say{negativa} de conexões onde tanto a entrada quanto a saída são \say{negativas}. Essa é uma das vantagens mais facilmente observáveis da utilização de dados bipolares (ao invés de binários) para a representação dos dados.


\vspace{3ex}
\subsubsection{Técnica de aprendizado}


Existem várias técnicas de implementação das regras de aprendizado existentes. A técnica abordada aqui nada mais é do que uma das formas mais simples e genéricas de se aplicar a regra de Hebb. O entendimento dessa técnica é crucial para a posterior compreensão das outras técnicas aplicadas nesse trabalho, que podem ser tomadas como simples variações mais elaboradas desta.

O aprendizado é dado na forma iterativa e \cite{Fausett94} nos fornece o seguinte algoritmo:

\begin{enumerate}
	\item Os pesos de todas conexões são inicializados com o valor 0.
	\item Para todos os conjuntos de entradas e saídas, repetem-se os passos 3-4.
	\setlength{\itemindent}{+.5in}
	\item Para cada conexão, calculamos a variação do seu respectivo peso pela equação 6.
	\item Cada peso é atualizado conforme calculado no passo 3.
\end{enumerate}

Para esclarecer um pouco mais o algoritmo acima mostrado, segue um exemplo \citep{Fausett94} de sua aplicação em uma rede real com representação bipolar, onde usa-se como parâmetros de entrada a função lógica E. Busca-se com essa rede descobrir os valores dos pesos das conexões que determinam a fronteira de decisão dessa função.

A função lógica E retorna um valor \say{positivo} apenas se ambas as entradas possuírem também um valor \say{positivo}. Assim sendo, montaremos a tabela verdade dessa função conforme a \autoref{tabverdadeE}. A representação gráfica dessa rede está mostrada na \autoref{redeNeuralE}.

\begin{table}[htbp]
\caption{Tabela Verdade para a função lógica E}
\setlength{\tabcolsep}{24pt}
\begin{center}
\begin{tabular}{c c c c c}
\multicolumn{3}{c}{Entradas} & & Saída \\
Bias & $X_1$ & $X_2$ & & Y \\
1 & 1 & 1 & & 1 \\
1 & 1 & -1 & & -1 \\
1 & -1 & 1 & & -1 \\
1 & -1 & -1 & & -1
\end{tabular}
\end{center}
\label{tabverdadeE}
\end{table}

\begin{figure}[htbp]
	\centering
	  \includegraphics[angle=0, width=300pt, height=175pt]{D:/PFC/LaTex/Soccer-Wizard-LaTeX/figuras/redeNeuralE.jpg}
		\caption{RNA para a função lógica E}
	  \label{redeNeuralE}
\end{figure}

Iniciamos o treinamento conforme o passo 1 do algoritmo. Fazemos então os valores de $w_0=0, w_1=0$ e $w_2=0$.

Utilizaremos o primeiro par de entradas (1 ,1). Assim, calculamos o valor da variação dos pesos conforme a \autoref{HebbPesos}. O resultado é mostrado na \autoref{pesosPrimeiroPar}.

\begin{table}[h]
\caption{Variação dos pesos para o primeiro par de entradas}
\setlength{\tabcolsep}{18pt}
\begin{center}
\begin{tabular}{*{8}{c}}
\multicolumn{3}{c}{Entrada} & \multicolumn{2}{c}{Saída desejada} & \multicolumn{3}{c}{Variação dos pesos ($\Delta w$)} \\
1 & $X_1$ & $X_2$ & \multicolumn{2}{c}{Y} & $\Delta w_0$ & $\Delta w_1$ & $\Delta w_2$ \\
1 & 1 & 1 & \multicolumn{2}{c}{1} & 1 & 1 & 1 \\
\end{tabular}
\end{center}
\label{pesosPrimeiroPar}
\end{table}

Na sequência, atualizamos os pesos com os resultados da \autoref{resultadosPrimeiroPar}.

\begin{equation} \label{resultadosPrimeiroPar}
\begin{cases}
w_0 = 0+\Delta w_0 = 1 \cr
w_1 = 0+\Delta w_1 = 1 \cr
w_2 = 0+\Delta w_2 = 1
\end{cases}
\end{equation}

Repetimos o procedimento para o segundo par de entradas (1, -1). Assim, calculamos o valor da variação dos pesos conforme a \autoref{HebbPesos}. O resultado é mostrado na \autoref{pesosSegundoPar}.

\begin{table}[h]
\caption{Variação dos pesos para o segundo par de entradas}
\setlength{\tabcolsep}{18pt}
\begin{center}
\begin{tabular}{*{8}{c}}
\multicolumn{3}{c}{Entrada} & \multicolumn{2}{c}{Saída desejada} & \multicolumn{3}{c}{Variação dos pesos ($\Delta w$)} \\
1 & $X_1$ & $X_2$ & \multicolumn{2}{c}{Y} & $\Delta w_0$ & $\Delta w_1$ & $\Delta w_2$ \\
1 & 1 & -1 & \multicolumn{2}{c}{-1} & -1 & -1 & 1 \\
\end{tabular}
\end{center}
\label{pesosSegundoPar}
\end{table}

Na sequência, atualizamos os pesos com os resultados da \autoref{resultadosSegundoPar}.

\begin{equation} \label{resultadosSegundoPar}
\begin{cases}
w_0 = 1+\Delta w_0 = 0 \cr
w_1 = 1+\Delta w_1 = 0 \cr
w_2 = 1+\Delta w_2 = 2
\end{cases}
\end{equation}

Repetimos o procedimento para o terceiro par de entradas (-1, 1). Calculamos o valor da variação dos pesos conforme a \autoref{HebbPesos}. O resultado é mostrado na \autoref{pesosTerceiroPar}.

\begin{table}[h]
\caption{Variação dos pesos para o terceiro par de entradas}
\setlength{\tabcolsep}{18pt}
\begin{center}
\begin{tabular}{*{8}{c}}
\multicolumn{3}{c}{Entrada} & \multicolumn{2}{c}{Saída desejada} & \multicolumn{3}{c}{Variação dos pesos ($\Delta w$)} \\
1 & $X_1$ & $X_2$ & \multicolumn{2}{c}{Y} & $\Delta w_0$ & $\Delta w_1$ & $\Delta w_2$ \\
1 & -1 & 1 & \multicolumn{2}{c}{-1} & -1 & 1 & -1 \\
\end{tabular}
\end{center}
\label{pesosTerceiroPar}
\end{table}

Na sequência, atualizamos os pesos com os resultados da \autoref{resultadosTerceiroPar}.

\begin{equation} \label{resultadosTerceiroPar}
\begin{cases}
w_0 = 0+\Delta w_0 = -1 \cr
w_1 = 0+\Delta w_1 = 1 \cr
w_2 = 2+\Delta w_2 = 1
\end{cases}
\end{equation}

Repetimos uma última vez o procedimento para o quarto par de entradas (-1, -1). Calculamos o valor da variação dos pesos conforme a \autoref{HebbPesos}. O resultado é mostrado na \autoref{pesosQuartoPar}.

\begin{table}[h]
\caption{Variação dos pesos para o quarto par de entradas}
\setlength{\tabcolsep}{18pt}
\begin{center}
\begin{tabular}{*{8}{c}}
\multicolumn{3}{c}{Entrada} & \multicolumn{2}{c}{Saída desejada} & \multicolumn{3}{c}{Variação dos pesos ($\Delta w$)} \\
1 & $X_1$ & $X_2$ & \multicolumn{2}{c}{Y} & $\Delta w_0$ & $\Delta w_1$ & $\Delta w_2$ \\
1 & -1 & -1 & \multicolumn{2}{c}{-1} & -1 & 1 & 1 \\
\end{tabular}
\end{center}
\label{pesosQuartoPar}
\end{table}

Na sequência, atualizamos os pesos com os resultados da \autoref{resultadosQuartoPar}.

\begin{equation} \label{resultadosQuartoPar}
\begin{cases}
w_0 = -1+\Delta w_0 = -2 \cr
w_1 = 1+\Delta w_1 = 2 \cr
w_2 = 1+\Delta w_2 = 2
\end{cases}
\end{equation}

Terminamos assim o treinamento e a rede resultante é mostrada na \autoref{EResolvida}.

\begin{figure}[htbp]
	\centering
	  \includegraphics[angle=0, width=300pt, height=175pt]{D:/PFC/LaTex/Soccer-Wizard-LaTeX/figuras/redeEresolvida.jpg}
		\caption{RNA resolvida para a função lógica \emph{E}}
	  \label{EResolvida}
\end{figure}

Essa configuração de pesos nos fornece uma fronteira de decisão em forma de reta, que pode ser encontrada utilizando a \autoref{equacaoReta}. A equação da reta resultante do exemplo acima é dada pela \autoref{retaResultado} e está mostrada na \autoref{fronteiraDecisaoE}.


\begin{equation} \label{equacaoReta}
1 + X_1 + X_2 = 0
\end{equation}

\begin{equation} \label{retaResultado}
X_2 = -X_1 + 1
\end{equation}

\begin{figure}[htbp]
	\centering
	  \includegraphics[angle=0, width=300pt, height=175pt]{D:/PFC/LaTex/Soccer-Wizard-LaTeX/figuras/fronteiraDecisaoE.png}
		\caption{Fronteira de decisão da função lógica \emph{E}}
	  \label{fronteiraDecisaoE}
\end{figure}

Podemos notar que apesar de os pesos terem sido alterados pelo último loop, a equação da reta (e consequentemente a fronteira de decisão) não é alterada após o mesmo. Isso significa que o treinamento já havia encontrado a solução do problema antes do fim do algoritmo. Como será mostrado mais adiante, outras técnicas de treinamento podem continuar indefinidamente, repetindo os vetores de entrada, refazendo os cálculos sem fim. Nesses casos, uma condição de parada deverá ser adotada.


\vspace{3ex}
\subsection{Perceptron} \label{Perceptron}


Redes com um modelo de treinamento iterativo e supervisionado foram propostas por Frank Rosenblatt em \citeyear{Rosenblatt62}. Ele as chamou de Perceptrons e elas tiveram um grande impacto nos estudos de redes neurais artificiais. Isso se deve ao fato de que a regra de convergência dos perceptrons é mais poderosa do que sua antecessora, a regra de Hebb. Além disso, sob determinadas condições, é possível provar matematicamente a convergência de seu procedimento de aprendizado iterativo. Basicamente, ela consiste de um simples neurônio com pesos sinápticos e bias ajustáveis.

\cite{Fausett94} cita um perceptron particularmente simples que utilizava valores binários de entrada e saída, contudo a função de ativação do neurônio de saída poderia retornar valores de -1, 0 ou 1 durante o aprendizado. A possibilidade de 3 diferentes valores só ocorre graças ao novo tipo de função de ativação, onde o valor do limiar passou a delimitar uma região intermediária, e não apenas um valor limítrofe entre saídas positivas e negativas. Essa função é descrita pela \autoref{funcaoAtivacaoPerceptron}, calculada com a ajuda da \autoref{entradaPerceptron}.

\begin{equation} \label{entradaPerceptron}
Y_{in} = \sum_i x_i \cdot w_i
\end{equation}

\begin{equation} \label{funcaoAtivacaoPerceptron}
f(Y_{in}) = \begin{cases}
1 & \text{se } Y_{in} > \theta \cr
0 & \text{se } -\theta \leq Y_{in} \leq \theta \cr
-1 & \text{se } Y_{in} < \theta \cr
\end{cases}
\end{equation}

Para se atualizar os pesos das ligações durante o treinamento usamos a \autoref{pesosPerceptron}. Tal equação apresenta um novo parâmetro, chamado de taxa de aprendizado, que é um valor constante determinado antes do início do treinamento.

\begin{equation} \label{pesosPerceptron}
\Delta w_i = \alpha \cdot x_i \cdot t
\end{equation}

O treinamento do perceptron continua até que os pesos das conexões sejam tais que para todos os padrões de entrada a resposta obtida pela rede seja correta. Segundo o teorema de convergência dos perceptrons, caso tais pesos existam, eles serão encontrados em um número finito de passos do treinamento.

Observando a função de ativação de saída, que retorna valores de -1, 0 ou 1, e a saída real (Target t) que deve ter valores de -1 ou 1, \cite{Fausett94} conclui alguns pontos importantes relacionados a esse perceptron:

\begin{itemize}
	\item A rede não diferencia situações onde, por exemplo, a saída real é -1 e a saída calculada é 0 ou 1. Em ambos os casos os pesos são atualizados de maneira igual e o sinal do erro informa se os mesmos devem aumentar ou diminuir.
	\item Apenas conexões de entrada com valores diferentes de 0 possuem seus pesos atualizados.
	\item Padrões de entrada que não produzem erro na saída também não têm seus pesos atualizados.
	\item Como o treinamento ocorre até que os pesos sejam tais que a saída seja correta para quaisquer padrões de entrada, e padrões sem erro não resultam em treinamento da rede, quanto mais treinada a rede estiver, menor será o seu aprendizado.
	\item O valor do limiar não mais fornece uma equação, delimitando uma fronteira de decisão, mas sim uma inequação, fornecendo uma região de \say{indecisão}, separando a região de respostas positivas e a região de respostas negativas. Dessa forma, o valor do limiar se torna mais significativo para o processo de aprendizagem.
\end{itemize}

Ao contrário das redes mostradas até agora, no perceptron o uso do limiar e do bias não são equivalentes. Como agora eles possuem funções diferentes, ambos são necessários para que o treinamento funcione corretamente.

\vspace{3ex}
\subsubsection{Técnica de aprendizado} 

O algoritmo de aprendizado do perceptron apresentado por \cite{Fausett94} está apresentado a seguir. Sua estrutura é semelhante à do treinamento de Hebb, porém já mais avançado e mais parecido com o algoritmo utilizado para a realização desse trabalho.
\begin{enumerate}
	\item Inicializar pesos e bias (podem ser setados em 0, por simplicidade)
	\item Definir taxa de aprendizado $0<\alpha<1$
	\item Enquanto a condição de parada não for atingida repetem-se os passos 4-7
	\setlength{\itemindent}{+.5in}
	\item Para todos os conjuntos de entradas e saídas repetem-se os passos 5-6
	\setlength{\itemindent}{+1in}
	\item Calcula-se o valor da saída de acordo com a \autoref{entradaPerceptron} e a \autoref{funcaoAtivacaoPerceptron}
	\item Caso a saída calculada seja diferente da saída correta atualizam-se os pesos de acordo com a \autoref{pesosPerceptron}
	\setlength{\itemindent}{+0.5in}
	\item Caso nenhum peso tenha sido alterado no passo 6, pare. Caso contrário, continue
\end{enumerate}
		
\vspace{3ex}
\subsection{Adaline} 


\cite{Widrow60} apresentaram um novo modelo de redes chamado Adaline, que é uma redução para Adaptive Linear Neuron (Neurônio Linear Adaptativo, em tradução livre). A inovação apresentada por eles se destaca pela regra de treinamento utilizada, a Regra Delta, também conhecida por Regra dos Mínimos Quadrados Médios (LMS) ou Regra de Widrow-Hoff.
A Regra Delta se mostra como uma inovação diante das opções anteriores à ela devido ao fato de que é capaz de fornecer correções pequenas e variáveis ao longo do treinamento. Seu desenvolvimento se deu com a ideia de que a mudança dos pesos da conexão deve minimizar a diferença entre a saída calculada Yin e o valor alvo t, minimizando o erro ao longo de todos os padrões de entrada. Isso é obtido se reduzindo o erro em cada padrão de entrada, um por vez. Para se atualizar os pesos das ligações usamos a \autoref{pesosAdaline}. Tal equação, assim como nos perceptrons, apresenta um parâmetro chamado de taxa de aprendizado, que é um valor constante determinado antes do início do treinamento.

\begin{equation} \label{entradaAdaline}
Y_{in} = \sum_i x_i \cdot w_i
\end{equation}

\begin{equation} \label{pesosAdaline}
\Delta w_i = \alpha \cdot x_i \cdot (t-Y_{in})
\end{equation}

Semelhantemente as redes já apresentadas, um Adaline tipicamente usa ativação bipolar para os sinais de entrada e saída, possui pesos ajustáveis nas conexões e também possui bias. Apesar da Regra Delta poder ser utilizada em redes com múltiplas saídas e/ou camadas, um Adaline é um caso especial onde existe apenas uma saída e uma camada.

A arquitetura de uma rede Adaline é mostrada na \autoref{Arquiteturaadaline}.

\begin{figure}[htbp]
	\centering
	  \includegraphics[angle=0, width=300pt, height=175pt]{D:/PFC/LaTex/Soccer-Wizard-LaTeX/figuras/Adaline.jpg}
		\caption{Arquitetura de uma Adaline \citep{Fausett94}}
	  \label{Arquiteturaadaline}
\end{figure}


\vspace{3ex}
\subsubsection{Técnica de aprendizado} 


O algoritmo de aprendizado do Adaline conforme mostrado por \cite{Fausett94} está apresentado a seguir. Sua estrutura não é muito diferente à do perceptron, contudo, possui uma mudança singela: os pesos aqui são alterados em todos loops de treinamento e o controle de parada se dá por um limiar máximo de alteração dos pesos. Como pode ser visto abaixo.

\begin{enumerate}
	\item Inicializar pesos e bias (podem ser setados em 0, por simplicidade)
	\item Definir taxa de aprendizado $0<\alpha<1$
	\item Enquanto a condição de parada não for atingida repetem-se os passos 4-7
	\setlength{\itemindent}{+.5in}
	\item Para todos os conjuntos de entradas e saídas repetem-se os passos 5-6
	\setlength{\itemindent}{+1in}
	\item Calcula-se o valor da saída de acordo com a \autoref{entradaAdaline}
	\item Atualizam-se os pesos de acordo com a \autoref{pesosAdaline}
	\setlength{\itemindent}{+0.5in}
	\item Caso a maior alteração de peso que ocorreu no passo 6 seja menor que um valor determinado, pare. Caso contrário, continue.
\end{enumerate}

A taxa de aprendizado deve ser determinada com cuidado. Um valor muito pequeno pode fazer com que a rede seja treinada muito lentamente, e de forma oposta, um valor muito grande pode fazer com que o treinamento não convirja. \cite{Hecht-Nielsen90} chegou a uma equação para limitar o valor da taxa de aprendizado. Porém, é mais comum simplesmente a escolha de um valor inicial pequeno (0,1 por exemplo).

	Um outro ponto importante desse treinamento se deve ao fato de que a aplicação da rede em situações que a saída deve ser bivalente não pode ser apenas uma repetição de parte do algoritmo de treinamento, pois o mesmo retornaria valores quebrados. Assim, a aplicação do Adaline em tais situações requer uma função de ativação para poder ser usada. Comumente a função degrau é utilizada para tais aplicações.


\vspace{3ex}
\subsection{Redes Multicamadas}

Muitas vezes, uma rede neural de apenas uma camada, como as mostradas até agora, não é capaz de solucionar o problema proposto \citep{Haykin99}. Tais limitações foram um dos fatores que reduziram o interesse nas redes neurais artificiais nos anos 70. Para tentar solucionar esses casos, foram desenvolvidas as redes multicamadas (\autoref{redesMulticamadas}). Nesse trabalho serão expostas as redes Madaline e Multilayer Perceptron com BackPropagation, que são extensões multicamadas das redes Adaline e Perceptron, respectivamente.

\begin{figure}[htbp]
	\centering
	  \includegraphics[angle=0, width=400pt, height=225pt]{D:/PFC/LaTex/Soccer-Wizard-LaTeX/figuras/redesMulticamadas.jpg}
		\caption{Arquitetura de uma rede multicamadas com duas camadas intermediárias \citep{Haykin99}}
	  \label{redesMulticamadas}
\end{figure}


\vspace{3ex}
\subsection{Madaline}

Segundo \cite{Fausett94} o uso das redes Adaline em uma configuração multicamadas é possível, e chamado Madaline - Many Adaptive Linear Neurons (Muitos Neurônios Lineares Adaptativos, em tradução livre).

Um modelo simples de uma Madaline pode ser visto na \autoref{arquiteturaMadaline}. Nela, temos dois neurônios de entrada (X1 e X2), duas Adalines resultando dois neurônios intermediários (Z1 e Z2) e uma terceira Adaline, que utiliza os neurônios intermediários (aqui chamados NI) como entradas e resulta a saída Y. Podemos ver que cada uma das três Adalines intermediarias precisam de um bias.

\begin{figure}[htbp]
	\centering
	  \includegraphics[angle=0, width=300pt, height=200pt]{D:/PFC/LaTex/Soccer-Wizard-LaTeX/figuras/Madaline.jpg}
		\caption{Arquitetura de uma Madaline com uma camada intermediária de dois neurônios \citep{Fausett94}}
	  \label{arquiteturaMadaline}
\end{figure}

O processo de treinamento de uma Madaline não sofre grandes alterações em relação à sua versão mais simples, de uma camada. Basicamente, a rede é uma combinação de várias Adalines, assim como seu processo de treinamento também é a combinação do processo de treinamento de várias Adalines. Assim sendo, o mesmo algoritmo já mostrado é apenas repetido para cada pedaço da rede multicamadas.

Devemos, entretanto, levar em conta que as entradas do sistema são utilizadas apenas pelas Adalines que resultam a primeira camada intermediária. Por sua vez, a primeira camada intermediária fornece as entradas para as Adalines que resultam a segunda camada intermediária, e assim sucessivamente, até que se chegue na saída do sistema.


\vspace{3ex}
\subsection{Backpropagation}

O uso de perceptrons multicamadas, com a regra de treinamento supervisionado de Backpropagation (retro propagação de erros) ou Regra Delta Generalizada, tem sido amplo e eficaz na resolução de problemas, por vezes complexos, em diversas áreas. Apesar de sua importância atual, não se diz que o Backpropagation possui um criador, pois foi desenvolvido simultaneamente por diversos pesquisadores. Esse método visa reduzir o gradiente do erro quadrático total da saída da rede ao longo do treinamento, ou seja, minimizando o erro da saída calculado pelo sistema \citep{Fausett94}.

O algoritmo utilizado nesse trabalho usa a regra de Backpropagation. O objetivo é treinar a rede para alcançar um balanço entre a habilidade de responder corretamente a padrões de entrada (utilizados para treinamento) e a habilidade de responder bem a entradas similares, mas não necessariamente idênticas, às utilizadas no treinamento.

Podemos dizer que o Backpropagation utiliza o melhor de cada um dos modelos de redes neurais já apresentados. Em sua base temos uma arquitetura multicamadas, baseada em Perceptrons (\autoref{arquiteturaBackpropagation}). A regra de treinamento utilizada é a Regra Delta Generalizada, que é uma modificação da Regra Delta. Além disso, possui a retro propagação do erro, que visa uma redução gradual do erro ao longo do treinamento.


\begin{figure}[htbp]
	\centering
	  \includegraphics[angle=0, width=450pt, height=300pt]{D:/PFC/LaTex/Soccer-Wizard-LaTeX/figuras/Backpropagation.jpg}
		\caption{Arquitetura de uma rede Backpropagation com uma camada intermediária de $P$ neurônios. \citep{Fausett94}}
	  \label{arquiteturaBackpropagation}
\end{figure}


\vspace{3ex}
\subsubsection{Treinamento e Aplicação}

Treinar uma rede com Backpropagation pode ser uma tarefa lenta mas, uma vez treinada, os resultados da rede são produzidos rapidamente \citep{Fausett94}. Para realizar o treinamento temos 3 estágios: Feedforward (Alimentação); Backpropagation (Retro Propagação); Ajuste de Pesos.

Na Alimentação, cada neurônio da primeira camada recebe seu valor de entrada e reproduz seu resultado para todos neurônios da camada seguinte, de acordo com sua função de ativação. Os neurônios das camadas intermediárias seguem o mesmo comportamento, e propagam o resultado da rede através de todas camadas existentes até os neurônios de saída.

Na Retro Propagação, é calculado o erro obtido entre o resultado da etapa de alimentação e o valor correto esperado. Esse erro é então retro propagado para toda a rede de acordo com um fator específico.

No Ajuste de Pesos, o erro que foi retro propagado é então utilizado para se calcular o ajuste que deve ser feito no peso de cada uma das conexões. Com as correções calculadas, todos os pesos das conexões da rede são atualizados simultaneamente.
	
A aplicação da rede, por sua vez, se torna tarefa simples após o treinamento. Com os valores finais dos pesos das conexões, basta aplicarmos a primeira etapa do treinamento (Feedforward) com os valores de entrada desejados.


\vspace{3ex}
\subsubsection{Técnica de Aprendizado}

A técnica de aprendizado Backpropagation está apresentada a seguir conforme mostrado por \cite{Fausett94}. Sua estrutura é a mais complexa e avançada presente nesse trabalho. Também é importante citar que o algoritmo mostrado a seguir foi utilizado para se montar a parte prática desse trabalho.

As equações utilizadas no algoritmo mostrado abaixo são descritas a seguir. A nomenclatura utilizada por ser vista na \autoref{arquiteturaBackpropagation}, para uma melhor ilustração de sua representação. Uma explicação do que cada equação representa é dada em sequência.

\begin{equation} \label{back1}
Y_{in} = \sum_i x_i \cdot w_i
\end{equation}

\begin{equation} \label{back2}
Y_{out} = f(Y_{in})
\end{equation}

\begin{equation} \label{back3}
\delta_z = (t - Z_{out}) \cdot f'(Z_{in})
\end{equation}

\begin{equation} \label{back4}
\Delta w_{yz} = \alpha \cdot Y_{out} \cdot \delta_z
\end{equation}

\begin{equation} \label{back5}
\delta_{in} = \sum_i \delta_i \cdot w_i
\end{equation}

\begin{equation} \label{back6}
\delta_y = \delta_{in} \cdot f'(Y_{in})
\end{equation}

\begin{equation} \label{back7}
\Delta w_{xy} = \alpha \cdot X_{out} \cdot \delta_y
\end{equation}

\begin{equation} \label{back8}
w_{novo} = w_{velho} + \Delta w
\end{equation}

A \autoref{back1} fornece o valor que chega a cada um dos neurônios, sendo o resultado da somatória dos valores fornecidos por cada conexão que \say{chega} no neurônio. O valor fornecido por cada conexão é o resultado do valor de seu neurônio de origem multiplicado pelo peso da conexão.

A \autoref{back2} fornece o valor que \say{sai} de cada neurônio. Tal valor é obtido ao se aplicar a função de ativação utilizada ao valor obtido na \autoref{back1}.

A \autoref{back3} fornece o \say{fator de informação do erro} dos neurônios da última camada. Esse fator é obtido a partir da diferença entre o valor de saída esperado \say{$t$}  e o valor de saída obtido \say{$Z_{out}$}. Tal resultado é então multiplicado pelo valor de entrada do neurônio aplicado à derivada da função de ativação utilizada.

A \autoref{back4} fornece o \say{fator de correção do erro} das conexões que chegam aos neurônios da última camada. Esse valor é obtido através da multiplicação da taxa de aprendizado \say{$\alpha$} com o valor de saída do neurônio anterior da conexão \say{$Y_{out}$} com o fator de informação do erro do neurônio posterior da conexão \say{$\delta_z$}.

A \autoref{back5} fornece o valor retro propagado de erro que \say{chega} ao neurônio intermediário. Esse valor é obtido fazendo a somatória da multiplicação do fator de informação do erro \say{$\delta_i$} com o fator de correção do erro \say{$w_i$} através de todas as conexões posteriores ao neurônio.

A \autoref{back6} fornece o \say{fator de informação do erro} dos neurônios intermediários. Esse fator é obtido a partir da multiplicação do valor retro propagado de erro que \say{chega} ao neurônio \say{$\delta_{in}$} e o valor de entrada do neurônio \say{$Y_{in}$} aplicado à derivada da função de ativação utilizada.

A \autoref{back7} fornece o \say{fator de correção do erro} das conexões que chegam aos neurônios intermediários. Esse valor é obtido através da multiplicação da taxa de aprendizado \say{$\alpha$} com o valor de saída do neurônio anterior da conexão \say{$X_{out}$} com o fator de informação do erro do neurônio posterior da conexão \say{$\delta_y$}.

A \autoref{back8} fornece as diretrizes de atualização dos pesos de cada conexão. O valor do peso atualizado $w_{novo}$ corresponde à soma do peso antigo $w_{velho}$ com o fator de correção do erro da conexão.

Segue o algoritmo:
	
	
\begin{enumerate}
	\setlength{\parindent}{1in}
	\item Inicializar pesos e bias
	\item Enquanto a condição de parada não for atingida, repetem-se os passos 3-10.
	\setlength{\itemindent}{+.5in}
	\item Para todos pares de entradas e saídas, repetem-se os passos 4-9
	\setlength{\itemindent}{+1in}
	\vspace{2ex}
	
	(FeedForward - Alimentação)
	\item Os neurônios da primeira camada recebem o valor de entrada e os propagam para as camadas intermediárias.
	\item Os neurônios da segunda camada recebem os valores da camada anterior e calcula-se seus valores de entrada de acordo com a \autoref{back1}.
	\item A saída dos neurônios da segunda camada é então calculada de acordo com sua função de ativação, conforme a \autoref{back2}.
	O cálculo segue para todas as camadas intermediárias seguintes até que se compute a saída do sistema.
	\vspace{2ex}
	
	(Backpropagation - Retro Propagação)
	\item Cada neurônio de saída recebe um fator de informação do erro, calculado de acordo com a \autoref{back3}. Recebe também um fator de correção do erro, calculado de acordo com a \autoref{back4}.
	\item Cada neurônio intermediário calcula seu valor de entrada do erro retro propagado de acordo com a \autoref{back5}. Tal valor é multiplicado pela derivada de sua função de ativação para obter seu fator de informação de erro, conforme \autoref{back6}. Seu fator de correção do erro é calculado de acordo com a \autoref{back7}.
	
	(Ajuste de Pesos)
	\item Cada conexão tem seu peso atualizado, de acordo com a \autoref{back8}.

	\setlength{\itemindent}{+0.5in}
	\item Testar condição de parada
\end{enumerate}

Mais detalhes sobre os parâmetros utilizados e as escolhas que devem ser feitas para o treinamento, dentre eles o número de NIs e a função de ativação utilizada, serão mostrados no capítulo de Materiais e Métodos.

\vspace{3ex}
\section{Programação Orientada a Objetos} \label{Fund.POO}

Para a realização desse trabalho, foi necessária a criação de um programa de computador capaz de realizar os cálculos determinados pelo algoritmo de Backpropagation. A Programação Orientada a Objetos (POO) foi escolhida como paradigma para se escrever o código. Nela nos expressamos no código em termos de objetos, suas propriedades, métodos e estados.

Essa forma ou paradigma de programação foi escolhido por fornecer algumas vantagens essenciais necessárias ao longo do desenvolvimento do projeto. Entre elas podemos citar:

\begin{itemize}
	\item Possui uma base conceitual no campo de estudo da cognição, ou seja, tenta representar o mundo da forma mais real possível. Da mesma forma, a Inteligência Artificial também busca representar a inteligência humana da forma mais real possível, criando assim um vínculo conceitual entre ambas, o que facilita o desenvolvimento.
	\item Suas representações são facilmente visíveis no mundo real: como todas as representações são feitas em forma de objetos, a compreensão dos mesmos se torna mais clara e perceptível, tanto para o programador quanto para um usuário.
	\item Fácil manutenção: a POO possui a capacidade de encapsulamento dos objetos, tornando-os entidades únicas, com propriedades e funções únicas. O encapsulamento no código reduz drasticamente a chance de que uma parte do sistema interfira no funcionamento de outra, reduzindo assim uma das mais comuns fontes de erros em programas.
	\item Facilidade de evolução: o encapsulamento fornece também modularidade, facilitando o desenvolvimento do código através de reuso e extensão de componentes (módulos) já existentes.
\end{itemize}


\vspace{3ex}
\subsection{Java}

Java é uma linguagem de programação desenvolvida pela Sun Microsystems em 1995. Existem atualmente inúmeras aplicações, em incontáveis plataformas, utilizando essa linguagem, que é definida pela sua desenvolvedora da seguinte forma: \say{\textit{Java é uma linguagem simples, orientada a objetos, distribuída, interpretada, robusta, segura, independente de arquitetura, portável, de alto desempenho, suportando multithreads e dinâmica.}}

Das características citadas acima, podemos destacar algumas vantagens que foram determinantes para que Java fosse escolhida como a linguagem de programação a ser usada nesse trabalho.
	
\begin{itemize}
	\item Simplicidade: Java é considerada uma linguagem simples, com uma sintaxe baseada em C e C++, porém com diversas vantagens e melhorias em relação a essas. 
	\item Orientada a Objetos: utiliza o paradigma da POO, o que encaixa com o objetivo do projeto e permite uma analogia do mundo real muito mais clara e perceptível.
	\item Robusto: por ser destinada para escrever programas que devem ser confiáveis numa variedade de maneiras, a linguagem Java coloca muita ênfase na verificação precoce de possíveis problemas, em checagens dinâmicas em tempo de execução e na eliminação de situações que são propensas a erros.
	\item Multithread: multithreading é um modo de criação de aplicativos com vários segmentos ou processos em execução simultânea. Tal capacidade melhora a capacidade de resposta interativa do sistema e seu comportamento em tempo real, resultando em uma velocidade de execução aprimorada.
\end{itemize}


\vspace{3ex}
\section{Futebol de Campo} \label{Futebol}

O futebol de campo é um esporte de grande popularidade no mundo em geral, e principalmente no Brasil. Trata-se de um esporte coletivo com partidas que duram 90 minutos entre dois times de 11 jogadores cada.

Ele foi escolhido como tema desse trabalho por sua popularidade e por se tratar de um esporte considerado imprevisível.

Contudo, um certo padrão pode ser observado nos times mais vencedores. A quantidade de gols marcados e sofridos, o retrospecto jogando em \say{casa} e \say{fora de casa}, a relação entre número de vitórias, empates e derrotas, entre outros. Nesse trabalho busca-se reconhecer esses padrões e, a partir deles, determinar com certa assertividade o resultado de jogos futuros.


\vspace{3ex}
\subsection{Campeonato Brasileiro de Futebol}

O Brasileirão, como também é conhecido o Campeonato Brasileiro de Futebol, é o principal torneio entre clubes de futebol do Brasil. O torneio foi iniciado em 1971 e ocorre anualmente desde então.

O campeonato historicamente não tinha uma padronização no sistema de disputa, o que gerava mudanças frequentes de regras e de número de participantes. Contudo, a partir de 2003 o sistema de pontos corridos foi adotado e a partir de 2006 o número de times participantes foi reduzido a 20. Esse formato de pontos corridos com 20 times foi determinado como o \say{formato definitivo} pela Confederação Brasileira de Futebol (CBF) e assim vem sendo utilizado ao longo dos anos.

O formato da competição é determinado de forma que durante o decorrer da temporada (de maio a dezembro), cada clube joga duas vezes contra os outros (em um sistema de pontos corridos), uma vez em seu estádio e a outra no de seu adversário, em um total de 38 jogos. As equipes recebem três pontos por vitória e um por empate. Não são atribuídos pontos para derrotas.

As equipes são classificadas pelo total de pontos, depois pelo saldo de gols e, em seguida, pelos gols marcados. Em caso de empate entre dois ou mais clubes, os critérios de desempate são os seguintes: maior número de vitórias; maior saldo de gols; maior número de gols pró; confronto direto; menor número de cartões vermelhos recebidos; menor número de cartões amarelos recebidos.

O Campeonato Brasileiro de Futebol foi escolhido como tema de estudo por algumas de suas características, entre as quais podemos destacar:

\begin{itemize}
	\item Longa duração: por se tratar de um campeonato longo, é possível obter uma maior quantidade de informações para serem usadas no treinamento e/ou aplicação da Rede Neural Artificial, resultando em uma aplicação mais eficiente e confiável.
	\item Pontos corridos: o sistema de classificação em pontos permite uma melhor comparação entre as performances que os times vêm apresentando.
	\item Duas rodadas: além de aumentar a quantidade de jogos para análise, a dupla rodada permite adicionarmos mais um parâmetro de entrada, sendo esse a condição de partida \say{em casa} ou \say{fora de casa}.
	\item Vários Times: a quantidade de times permite diversas opções de confrontos, o que eleva as oportunidades de análise e aprendizado que a Rede Neural realiza.
	\item Proximidade e familiaridade: por ser um campeonato de conhecimento geral, com regras simples e conhecidas, e fontes de dados facilmente acessíveis, o Campeonato Brasileiro de Futebol se mostra como um campo de estudo \say{sem mistérios}.
	\item Sistema de disputa padronizado: desde 2006 o formato do campeonato é o mesmo, sem previsões de alterações, o que facilita a extensão da abordagem de um ano para o outro e a comparação dos resultados entre anos diferentes.
\end{itemize}

%
%
%
%
%
%
%
%
%
%